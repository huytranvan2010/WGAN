{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNZmY0wcNhygdiL4WLDTmsJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huytranvan2010/WGAN/blob/main/WGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVCv8iYiwkz4"
      },
      "source": [
        "Implement WGAN theo cách weight clipping trên bộ dữ liệu MNIST. Ở đây chỉ làm cho chữ số 7 để quá trình train nhanh hơn, có thể train cho tất cả tập dữ liệu và kiểm tra xem mode collapse có bị xảy ra không."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYSWIZmGwfID",
        "outputId": "ce968762-6d67-4f98-bc0c-481778c70d93"
      },
      "source": [
        "# import các thư việ cần thiết\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, BatchNormalization\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.constraints import Constraint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# xây dựng class kế thừa từ Constraint cho weight clipping\n",
        "class ClipConstraint(Constraint):\n",
        "\t# set clip value\n",
        "\tdef __init__(self, clip_value):\n",
        "\t\tself.clip_value = clip_value\n",
        "\n",
        "\t# clip weights\n",
        "\tdef __call__(self, weights):\n",
        "\t\treturn tf.clip_by_value(weights, -self.clip_value, self.clip_value)\n",
        "\n",
        "\t# trả về config\n",
        "\tdef get_config(self):\n",
        "\t\treturn {'clip_value': self.clip_value}\n",
        "\n",
        "# định nghĩa wasserstein loss\n",
        "def wasserstein_loss(y_true, y_pred):\n",
        "\treturn tf.reduce_mean(y_true * y_pred)\n",
        "\n",
        "# định nghĩa critic model\n",
        "def define_critic(in_shape=(28,28,1)):\n",
        "\t# khởi tạo weights\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# weight constraint\n",
        "\tconst = ClipConstraint(0.01)\n",
        "\t#  model\n",
        "\tmodel = Sequential()\n",
        " \n",
        "\t# giảm xuống 14x14\n",
        "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const, input_shape=in_shape))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        " \n",
        "\t# giảm xuống 7x7\n",
        "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        " \n",
        "\t# linear activation\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(1))\n",
        " \n",
        "\t# compile model\n",
        "\topt = RMSprop(learning_rate=0.00005)\n",
        "\tmodel.compile(loss=wasserstein_loss, optimizer=opt)\n",
        "\treturn model\n",
        "\n",
        "# định nghĩa generator model\n",
        "def define_generator(latent_dim):\n",
        "\t# khởi tạo weight\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        " \n",
        "\t# foundation for 7x7 image\n",
        "\tn_nodes = 128 * 7 * 7\n",
        "\tmodel.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Reshape((7, 7, 128)))\n",
        " \n",
        "\t# tăng kích thước lên 14x14\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        " \n",
        "\t# tăng kích thước lên 28x28\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        " \n",
        "\t# output 28x28x1 (dùng Conv layer với 1 kernel)\n",
        "\tmodel.add(Conv2D(1, (7,7), activation='tanh', padding='same', kernel_initializer=init))\n",
        "\treturn model\n",
        "\n",
        "# định nghĩa gan - để update generator\n",
        "def define_gan(generator, critic):\n",
        "\t# weights của critic bị freeze\n",
        "\tfor layer in critic.layers:\n",
        "\t\tif not isinstance(layer, BatchNormalization):\n",
        "\t\t\tlayer.trainable = False\n",
        "\tmodel = Sequential()\n",
        "\t# add generator\n",
        "\tmodel.add(generator)\n",
        "\t# add the critic\n",
        "\tmodel.add(critic)\n",
        "\t# compile model\n",
        "\topt = RMSprop(learning_rate=0.00005)\n",
        "\tmodel.compile(loss=wasserstein_loss, optimizer=opt)\n",
        "\treturn model\n",
        "\n",
        "# load ảnh thật\n",
        "def load_real_samples():\n",
        "\t# load dataset\n",
        "\t(trainX, trainy), (_, _) = mnist.load_data()\n",
        "\t# chọn indicies có nhãn là 7\n",
        "\tselected_ix = (trainy == 7)     # trả về array True, False\n",
        "\tX = trainX[selected_ix]         # lấy vị trí của selected_ix = True\n",
        "\t# mở rộng chiều về cuối - phù hợp cho Conv2D\n",
        "\tX = np.expand_dims(X, axis=-1)\n",
        "\t# chuyển từ uint8 => float\n",
        "\tX = X.astype('float32')\n",
        "\t# scale từ [0,255] về [-1,1] - layer cuối của generator dùng tanh\n",
        "\tX = (X - 127.5) / 127.5\n",
        "\treturn X\n",
        "\n",
        "# chọn ảnh thật vào minibatch\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\t# chọn ngẫu nhiên n_samples indicies\n",
        "\tix = np.random.randint(0, dataset.shape[0], n_samples)\n",
        "\t# lấy ảnh images\n",
        "\tX = dataset[ix]\n",
        "\t# tạo label = -1 for cho ảnh thật\n",
        "\ty = - np.ones((n_samples, 1))\n",
        "\treturn X, y\n",
        "\n",
        "# tạo points từ latent space làm đầu vào cho generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# tạo n_samples points cho minibatch\n",
        "\tx_input = np.random.randn(n_samples, latent_dim)\n",
        "\treturn x_input\n",
        "\n",
        "# sử dụng points trong latent space để tạo ảnh fake\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "\t# tạo points trong latent space\n",
        "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
        "\t# output của generator - ảnh fake\n",
        "\tX = generator.predict(x_input)\n",
        "\t# tạo labels = 1 cho ảnh fake\n",
        "\ty = np.ones((n_samples, 1))\n",
        "\treturn X, y\n",
        "\n",
        "# sinh dữ liệu and save as a plot and save the model\n",
        "def summarize_performance(step, g_model, latent_dim, n_samples=100):\n",
        "\t# prepare fake examples\n",
        "\tX, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "\t# scale from [-1,1] to [0,1]\n",
        "\tX = (X + 1) / 2.0\n",
        "\t# plot images\n",
        "\tfor i in range(10 * 10):    # in 100 ảnh\n",
        "\t\t# định nghĩa subplot\n",
        "\t\tplt.subplot(10, 10, 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tplt.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tplt.imshow(X[i, :, :, 0], cmap='gray_r')    # đầu ra là tensor 4 chiều, mình chỉ cần 2 chiều cho mỗi ảnh, chỉ số cuối = 0 do có 1 channel\n",
        "\t# save plot to file\n",
        "\tfilename1 = 'generated_plot_%04d.png' % (step+1)\n",
        "\tplt.savefig(filename1)\n",
        "\tplt.close()\n",
        "\t# save the generator model\n",
        "\tfilename2 = 'model_%04d.h5' % (step+1)\n",
        "\tg_model.save(filename2)\n",
        "\tprint('>Saved: %s and %s' % (filename1, filename2))\n",
        "\n",
        "# create a line plot of loss for the gan and save to file\n",
        "def plot_history(d1_hist, d2_hist, g_hist):\n",
        "\t# plot history\n",
        "\tplt.plot(d1_hist, label='crit_real')\n",
        "\tplt.plot(d2_hist, label='crit_fake')\n",
        "\tplt.plot(g_hist, label='gen')\n",
        "\tplt.legend()\n",
        "\tplt.savefig('plot_line_plot_loss.png')\n",
        "\tplt.close()\n",
        "\n",
        "# train the generator and critic\n",
        "def train(g_model, c_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=64, n_critic=5):\n",
        "\t# số lượng batches cho mỗi epoch\n",
        "\tbatch_per_epoch = dataset.shape[0] // n_batch\n",
        "\t# số lượng training iterations\n",
        "\tn_steps = batch_per_epoch * n_epochs\n",
        "\t# kích thước của nửa batch\n",
        "\thalf_batch = n_batch // 2\n",
        "\t# tạo empty lists để lưu các losses\n",
        "\tc1_hist, c2_hist, g_hist = list(), list(), list()\n",
        "\t# duyệt qua training iterations\n",
        "\tfor i in range(n_steps):\n",
        "\t\t# CẬP NHẬT critic\n",
        "\t\tc1_tmp, c2_tmp = list(), list()\n",
        "\t\tfor _ in range(n_critic):\n",
        "\t\t\t# lấy ảnh thật\n",
        "\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "\t\t\t# update critic weights\n",
        "\t\t\tc_loss1 = c_model.train_on_batch(X_real, y_real)    # do ở trên ko định nghĩa metrics nên trin_on_batch chỉ trả về loss\n",
        "\t\t\tc1_tmp.append(c_loss1)\n",
        "\t\t\t# tạo ảnh fake\n",
        "\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\t\t# update critic weights\n",
        "\t\t\tc_loss2 = c_model.train_on_batch(X_fake, y_fake)\n",
        "\t\t\tc2_tmp.append(c_loss2)\n",
        "   \n",
        "\t\t# lưu critic loss\n",
        "\t\tc1_hist.append(np.mean(c1_tmp))     # lấy trung bình cho n_critic lần\n",
        "\t\tc2_hist.append(np.mean(c2_tmp))\n",
        "  \n",
        "        # CẬP NHẬT generator\n",
        "\t\t# tạo points trong latent space\n",
        "\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
        "\t\t# gán nhãn cho ảnh fake tại đây là -1 do đang muốn generator tạo ra ảnh giống thật nhất (gán nhãn giống ảnh thật)\n",
        "\t\ty_gan = - np.ones((n_batch, 1))\n",
        "\t\t# cập nhật generator thông qua critic \n",
        "\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "        # lưu lại loss\n",
        "\t\tg_hist.append(g_loss)\n",
        "  \n",
        "\t\t# in ra các loss\n",
        "\t\tprint('>%d, c1=%.3f, c2=%.3f g=%.3f' % (i+1, c1_hist[-1], c2_hist[-1], g_loss))\n",
        "\t\t# đánh giá model sau mỗi \"epoch\" (thực hiện được số batches trong 1 epoch)\n",
        "\t\tif (i+1) % batch_per_epoch == 0:\n",
        "\t\t\tsummarize_performance(i, g_model, latent_dim)\n",
        "\t# line plots of loss\n",
        "\tplot_history(c1_hist, c2_hist, g_hist)\n",
        "\n",
        "# số chiều của points trong latent space\n",
        "latent_dim = 50\n",
        "# Tạo critic\n",
        "critic = define_critic()\n",
        "# Tạo generator\n",
        "generator = define_generator(latent_dim)\n",
        "# tạo gan\n",
        "gan_model = define_gan(generator, critic)\n",
        "# load ảnh thật\n",
        "dataset = load_real_samples()\n",
        "print(dataset.shape)\n",
        "# train model\n",
        "train(generator, critic, gan_model, dataset, latent_dim)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(6265, 28, 28, 1)\n",
            ">1, c1=-2.476, c2=-0.011 g=0.250\n",
            ">2, c1=-6.971, c2=0.075 g=-1.079\n",
            ">3, c1=-9.931, c2=0.158 g=-2.317\n",
            ">4, c1=-12.631, c2=0.227 g=-3.253\n",
            ">5, c1=-14.191, c2=0.309 g=-4.490\n",
            ">6, c1=-16.575, c2=0.371 g=-5.054\n",
            ">7, c1=-17.585, c2=0.448 g=-5.845\n",
            ">8, c1=-18.548, c2=0.527 g=-6.841\n",
            ">9, c1=-20.347, c2=0.575 g=-7.947\n",
            ">10, c1=-21.509, c2=0.648 g=-8.445\n",
            ">11, c1=-22.465, c2=0.725 g=-9.050\n",
            ">12, c1=-23.194, c2=0.767 g=-10.263\n",
            ">13, c1=-24.587, c2=0.875 g=-10.956\n",
            ">14, c1=-25.302, c2=0.938 g=-11.672\n",
            ">15, c1=-26.249, c2=1.029 g=-12.786\n",
            ">16, c1=-26.067, c2=1.138 g=-13.969\n",
            ">17, c1=-27.435, c2=1.215 g=-14.983\n",
            ">18, c1=-27.844, c2=1.310 g=-15.024\n",
            ">19, c1=-28.405, c2=1.400 g=-15.952\n",
            ">20, c1=-28.853, c2=1.440 g=-16.817\n",
            ">21, c1=-28.871, c2=1.515 g=-17.759\n",
            ">22, c1=-30.255, c2=1.552 g=-18.183\n",
            ">23, c1=-30.413, c2=1.598 g=-18.772\n",
            ">24, c1=-31.355, c2=1.577 g=-19.463\n",
            ">25, c1=-31.304, c2=1.579 g=-19.667\n",
            ">26, c1=-32.505, c2=1.514 g=-20.393\n",
            ">27, c1=-32.572, c2=1.405 g=-20.537\n",
            ">28, c1=-32.558, c2=1.276 g=-21.990\n",
            ">29, c1=-33.758, c2=1.054 g=-21.740\n",
            ">30, c1=-34.145, c2=0.804 g=-22.613\n",
            ">31, c1=-34.372, c2=0.521 g=-23.393\n",
            ">32, c1=-35.397, c2=0.088 g=-24.107\n",
            ">33, c1=-35.363, c2=-0.324 g=-23.736\n",
            ">34, c1=-36.291, c2=-0.931 g=-25.370\n",
            ">35, c1=-36.732, c2=-1.651 g=-25.465\n",
            ">36, c1=-37.514, c2=-2.465 g=-27.254\n",
            ">37, c1=-36.664, c2=-3.588 g=-26.962\n",
            ">38, c1=-38.227, c2=-4.563 g=-27.907\n",
            ">39, c1=-37.969, c2=-5.766 g=-29.232\n",
            ">40, c1=-38.308, c2=-6.688 g=-29.418\n",
            ">41, c1=-39.542, c2=-8.098 g=-29.718\n",
            ">42, c1=-39.841, c2=-9.539 g=-30.941\n",
            ">43, c1=-39.996, c2=-11.139 g=-31.416\n",
            ">44, c1=-39.982, c2=-12.489 g=-32.283\n",
            ">45, c1=-40.478, c2=-13.955 g=-33.289\n",
            ">46, c1=-42.007, c2=-15.694 g=-34.229\n",
            ">47, c1=-42.550, c2=-16.980 g=-34.739\n",
            ">48, c1=-41.833, c2=-18.683 g=-36.282\n",
            ">49, c1=-43.479, c2=-20.007 g=-36.296\n",
            ">50, c1=-43.584, c2=-21.442 g=-37.026\n",
            ">51, c1=-44.210, c2=-22.955 g=-38.581\n",
            ">52, c1=-45.560, c2=-24.325 g=-39.409\n",
            ">53, c1=-44.667, c2=-25.585 g=-39.625\n",
            ">54, c1=-46.454, c2=-26.629 g=-40.171\n",
            ">55, c1=-46.929, c2=-28.045 g=-41.788\n",
            ">56, c1=-46.714, c2=-28.986 g=-42.885\n",
            ">57, c1=-48.351, c2=-30.190 g=-43.208\n",
            ">58, c1=-48.478, c2=-30.973 g=-44.389\n",
            ">59, c1=-48.883, c2=-32.520 g=-44.628\n",
            ">60, c1=-49.446, c2=-33.037 g=-45.299\n",
            ">61, c1=-50.278, c2=-34.541 g=-46.749\n",
            ">62, c1=-50.077, c2=-35.131 g=-47.165\n",
            ">63, c1=-51.612, c2=-36.403 g=-47.916\n",
            ">64, c1=-52.256, c2=-37.206 g=-49.355\n",
            ">65, c1=-52.670, c2=-38.054 g=-49.998\n",
            ">66, c1=-53.518, c2=-39.119 g=-50.568\n",
            ">67, c1=-53.976, c2=-39.765 g=-51.506\n",
            ">68, c1=-55.285, c2=-40.821 g=-51.444\n",
            ">69, c1=-56.029, c2=-41.658 g=-52.931\n",
            ">70, c1=-56.209, c2=-42.462 g=-54.524\n",
            ">71, c1=-56.891, c2=-43.371 g=-54.280\n",
            ">72, c1=-57.815, c2=-44.103 g=-55.379\n",
            ">73, c1=-58.960, c2=-45.176 g=-55.796\n",
            ">74, c1=-59.085, c2=-45.643 g=-57.186\n",
            ">75, c1=-58.434, c2=-46.871 g=-58.052\n",
            ">76, c1=-60.216, c2=-47.214 g=-58.438\n",
            ">77, c1=-61.338, c2=-48.552 g=-59.396\n",
            ">78, c1=-62.410, c2=-48.948 g=-60.239\n",
            ">79, c1=-62.817, c2=-50.166 g=-61.300\n",
            ">80, c1=-62.342, c2=-50.574 g=-62.379\n",
            ">81, c1=-63.454, c2=-51.487 g=-62.410\n",
            ">82, c1=-64.888, c2=-52.357 g=-63.473\n",
            ">83, c1=-65.100, c2=-52.825 g=-64.337\n",
            ">84, c1=-66.149, c2=-54.054 g=-65.287\n",
            ">85, c1=-66.731, c2=-54.502 g=-66.190\n",
            ">86, c1=-66.996, c2=-55.538 g=-66.699\n",
            ">87, c1=-68.133, c2=-55.956 g=-66.702\n",
            ">88, c1=-68.493, c2=-57.113 g=-68.933\n",
            ">89, c1=-69.343, c2=-57.374 g=-69.490\n",
            ">90, c1=-69.669, c2=-58.625 g=-70.280\n",
            ">91, c1=-70.813, c2=-59.036 g=-71.590\n",
            ">92, c1=-71.280, c2=-59.916 g=-72.094\n",
            ">93, c1=-71.997, c2=-60.622 g=-73.049\n",
            ">94, c1=-72.570, c2=-61.256 g=-73.366\n",
            ">95, c1=-72.983, c2=-62.379 g=-74.043\n",
            ">96, c1=-74.071, c2=-62.698 g=-75.135\n",
            ">97, c1=-75.015, c2=-63.770 g=-76.076\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: generated_plot_0097.png and model_0097.h5\n",
            ">98, c1=-75.637, c2=-64.302 g=-76.596\n",
            ">99, c1=-75.885, c2=-65.301 g=-77.442\n",
            ">100, c1=-76.777, c2=-65.802 g=-78.343\n",
            ">101, c1=-77.729, c2=-66.722 g=-79.045\n",
            ">102, c1=-78.578, c2=-67.585 g=-79.967\n",
            ">103, c1=-79.688, c2=-68.306 g=-80.197\n",
            ">104, c1=-80.055, c2=-69.255 g=-81.565\n",
            ">105, c1=-79.366, c2=-69.431 g=-82.770\n",
            ">106, c1=-81.314, c2=-70.725 g=-83.601\n",
            ">107, c1=-81.324, c2=-71.176 g=-84.427\n",
            ">108, c1=-81.886, c2=-72.198 g=-84.701\n",
            ">109, c1=-83.078, c2=-72.923 g=-85.992\n",
            ">110, c1=-83.610, c2=-73.356 g=-86.653\n",
            ">111, c1=-84.048, c2=-74.641 g=-86.883\n",
            ">112, c1=-85.267, c2=-75.159 g=-88.457\n",
            ">113, c1=-86.160, c2=-76.056 g=-89.226\n",
            ">114, c1=-86.708, c2=-76.544 g=-90.460\n",
            ">115, c1=-87.532, c2=-77.620 g=-90.744\n",
            ">116, c1=-88.930, c2=-78.057 g=-91.581\n",
            ">117, c1=-88.826, c2=-79.051 g=-92.416\n",
            ">118, c1=-90.100, c2=-79.715 g=-93.506\n",
            ">119, c1=-89.488, c2=-80.349 g=-93.936\n",
            ">120, c1=-91.128, c2=-81.450 g=-94.869\n",
            ">121, c1=-91.835, c2=-82.076 g=-96.243\n",
            ">122, c1=-92.579, c2=-82.727 g=-97.212\n",
            ">123, c1=-92.640, c2=-83.650 g=-97.382\n",
            ">124, c1=-93.355, c2=-84.497 g=-98.438\n",
            ">125, c1=-93.916, c2=-84.700 g=-99.458\n",
            ">126, c1=-94.828, c2=-85.965 g=-100.176\n",
            ">127, c1=-96.010, c2=-86.524 g=-100.813\n",
            ">128, c1=-96.538, c2=-87.616 g=-102.348\n",
            ">129, c1=-97.798, c2=-88.065 g=-102.930\n",
            ">130, c1=-98.782, c2=-89.078 g=-103.870\n",
            ">131, c1=-98.716, c2=-89.428 g=-103.822\n",
            ">132, c1=-99.751, c2=-90.767 g=-105.269\n",
            ">133, c1=-101.083, c2=-91.283 g=-106.047\n",
            ">134, c1=-101.006, c2=-92.274 g=-107.030\n",
            ">135, c1=-101.264, c2=-92.915 g=-107.560\n",
            ">136, c1=-103.101, c2=-93.754 g=-108.883\n",
            ">137, c1=-102.919, c2=-94.300 g=-109.869\n",
            ">138, c1=-104.365, c2=-95.053 g=-110.465\n",
            ">139, c1=-104.586, c2=-96.184 g=-111.306\n",
            ">140, c1=-105.812, c2=-96.652 g=-111.852\n",
            ">141, c1=-106.439, c2=-97.642 g=-112.651\n",
            ">142, c1=-107.156, c2=-98.346 g=-113.866\n",
            ">143, c1=-107.788, c2=-99.123 g=-114.823\n",
            ">144, c1=-108.756, c2=-99.805 g=-115.311\n",
            ">145, c1=-109.346, c2=-101.059 g=-116.091\n",
            ">146, c1=-110.099, c2=-101.329 g=-116.017\n",
            ">147, c1=-111.204, c2=-102.502 g=-117.688\n",
            ">148, c1=-110.754, c2=-102.894 g=-118.691\n",
            ">149, c1=-112.888, c2=-103.687 g=-119.316\n",
            ">150, c1=-112.859, c2=-104.636 g=-120.651\n",
            ">151, c1=-113.190, c2=-105.126 g=-121.315\n",
            ">152, c1=-114.812, c2=-105.973 g=-121.924\n",
            ">153, c1=-116.078, c2=-106.931 g=-122.764\n",
            ">154, c1=-116.708, c2=-107.851 g=-123.697\n",
            ">155, c1=-117.981, c2=-108.711 g=-124.374\n",
            ">156, c1=-118.255, c2=-109.322 g=-125.646\n",
            ">157, c1=-118.707, c2=-110.012 g=-125.543\n",
            ">158, c1=-119.415, c2=-111.332 g=-126.579\n",
            ">159, c1=-120.138, c2=-111.407 g=-128.138\n",
            ">160, c1=-120.346, c2=-112.251 g=-129.001\n",
            ">161, c1=-121.692, c2=-113.150 g=-129.629\n",
            ">162, c1=-122.532, c2=-114.147 g=-130.203\n",
            ">163, c1=-122.941, c2=-115.173 g=-131.200\n",
            ">164, c1=-124.020, c2=-115.866 g=-132.237\n",
            ">165, c1=-124.200, c2=-116.370 g=-132.407\n",
            ">166, c1=-124.921, c2=-117.667 g=-133.553\n",
            ">167, c1=-126.557, c2=-117.966 g=-134.574\n",
            ">168, c1=-127.932, c2=-119.062 g=-135.475\n",
            ">169, c1=-128.176, c2=-119.758 g=-136.339\n",
            ">170, c1=-128.557, c2=-120.367 g=-135.884\n",
            ">171, c1=-129.814, c2=-121.968 g=-137.604\n",
            ">172, c1=-130.550, c2=-122.075 g=-138.883\n",
            ">173, c1=-131.527, c2=-122.515 g=-139.052\n",
            ">174, c1=-132.524, c2=-124.091 g=-140.254\n",
            ">175, c1=-132.303, c2=-124.748 g=-140.836\n",
            ">176, c1=-133.107, c2=-125.873 g=-141.562\n",
            ">177, c1=-135.538, c2=-126.744 g=-143.054\n",
            ">178, c1=-135.533, c2=-127.006 g=-144.094\n",
            ">179, c1=-135.797, c2=-127.877 g=-143.994\n",
            ">180, c1=-137.819, c2=-129.119 g=-145.403\n",
            ">181, c1=-136.628, c2=-129.192 g=-145.959\n",
            ">182, c1=-138.260, c2=-130.456 g=-146.645\n",
            ">183, c1=-139.540, c2=-131.558 g=-147.880\n",
            ">184, c1=-140.249, c2=-131.897 g=-148.693\n",
            ">185, c1=-140.959, c2=-133.049 g=-149.614\n",
            ">186, c1=-141.351, c2=-133.501 g=-150.313\n",
            ">187, c1=-142.057, c2=-134.513 g=-151.330\n",
            ">188, c1=-144.406, c2=-135.435 g=-152.338\n",
            ">189, c1=-143.678, c2=-135.812 g=-153.303\n",
            ">190, c1=-144.517, c2=-136.586 g=-153.835\n",
            ">191, c1=-145.787, c2=-137.559 g=-154.677\n",
            ">192, c1=-146.464, c2=-138.618 g=-155.580\n",
            ">193, c1=-146.200, c2=-139.339 g=-155.685\n",
            ">194, c1=-148.836, c2=-140.756 g=-157.056\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: generated_plot_0194.png and model_0194.h5\n",
            ">195, c1=-148.143, c2=-140.326 g=-157.008\n",
            ">196, c1=-150.232, c2=-142.358 g=-159.048\n",
            ">197, c1=-149.939, c2=-142.619 g=-159.819\n",
            ">198, c1=-151.481, c2=-143.479 g=-160.742\n",
            ">199, c1=-151.736, c2=-144.302 g=-161.424\n",
            ">200, c1=-153.060, c2=-144.995 g=-162.555\n",
            ">201, c1=-153.606, c2=-146.213 g=-163.204\n",
            ">202, c1=-154.725, c2=-147.036 g=-164.083\n",
            ">203, c1=-157.117, c2=-147.875 g=-165.323\n",
            ">204, c1=-155.934, c2=-148.489 g=-165.969\n",
            ">205, c1=-156.874, c2=-149.361 g=-166.764\n",
            ">206, c1=-159.071, c2=-149.656 g=-167.918\n",
            ">207, c1=-158.319, c2=-150.704 g=-168.271\n",
            ">208, c1=-159.746, c2=-152.154 g=-169.054\n",
            ">209, c1=-160.702, c2=-153.095 g=-170.123\n",
            ">210, c1=-161.701, c2=-153.613 g=-171.188\n",
            ">211, c1=-162.182, c2=-154.235 g=-172.126\n",
            ">212, c1=-163.163, c2=-154.957 g=-172.636\n",
            ">213, c1=-163.498, c2=-156.508 g=-173.266\n",
            ">214, c1=-164.079, c2=-157.447 g=-174.512\n",
            ">215, c1=-166.279, c2=-157.736 g=-175.393\n",
            ">216, c1=-167.962, c2=-159.231 g=-176.588\n",
            ">217, c1=-168.011, c2=-158.659 g=-177.264\n",
            ">218, c1=-167.572, c2=-160.142 g=-176.604\n",
            ">219, c1=-169.162, c2=-162.235 g=-178.625\n",
            ">220, c1=-170.700, c2=-161.983 g=-179.435\n",
            ">221, c1=-172.066, c2=-163.515 g=-180.518\n",
            ">222, c1=-171.127, c2=-163.057 g=-181.663\n",
            ">223, c1=-172.092, c2=-164.457 g=-181.621\n",
            ">224, c1=-174.011, c2=-166.323 g=-183.416\n",
            ">225, c1=-174.315, c2=-166.381 g=-184.474\n",
            ">226, c1=-174.367, c2=-167.527 g=-185.070\n",
            ">227, c1=-176.611, c2=-168.313 g=-185.573\n",
            ">228, c1=-176.851, c2=-169.360 g=-187.126\n",
            ">229, c1=-178.082, c2=-169.985 g=-187.496\n",
            ">230, c1=-178.461, c2=-171.133 g=-188.722\n",
            ">231, c1=-179.756, c2=-171.744 g=-189.843\n",
            ">232, c1=-181.108, c2=-172.136 g=-189.805\n",
            ">233, c1=-181.478, c2=-174.147 g=-191.587\n",
            ">234, c1=-181.934, c2=-174.062 g=-192.138\n",
            ">235, c1=-183.650, c2=-175.379 g=-193.448\n",
            ">236, c1=-183.795, c2=-175.844 g=-193.905\n",
            ">237, c1=-183.934, c2=-177.124 g=-195.010\n",
            ">238, c1=-186.184, c2=-177.767 g=-195.788\n",
            ">239, c1=-185.439, c2=-178.761 g=-196.883\n",
            ">240, c1=-187.739, c2=-178.681 g=-197.440\n",
            ">241, c1=-189.000, c2=-180.674 g=-198.586\n",
            ">242, c1=-188.455, c2=-181.413 g=-199.250\n",
            ">243, c1=-190.327, c2=-182.595 g=-200.369\n",
            ">244, c1=-190.656, c2=-181.772 g=-201.349\n",
            ">245, c1=-190.804, c2=-182.963 g=-201.844\n",
            ">246, c1=-193.285, c2=-184.786 g=-203.049\n",
            ">247, c1=-191.766, c2=-184.499 g=-203.130\n",
            ">248, c1=-193.492, c2=-187.110 g=-203.734\n",
            ">249, c1=-193.318, c2=-188.703 g=-205.402\n",
            ">250, c1=-196.695, c2=-188.705 g=-206.780\n",
            ">251, c1=-197.158, c2=-189.231 g=-207.271\n",
            ">252, c1=-197.324, c2=-190.578 g=-208.461\n",
            ">253, c1=-199.820, c2=-189.907 g=-209.127\n",
            ">254, c1=-199.145, c2=-191.457 g=-209.923\n",
            ">255, c1=-201.937, c2=-191.754 g=-210.973\n",
            ">256, c1=-200.506, c2=-193.875 g=-212.074\n",
            ">257, c1=-202.882, c2=-193.802 g=-212.526\n",
            ">258, c1=-203.457, c2=-196.310 g=-213.379\n",
            ">259, c1=-203.776, c2=-197.413 g=-215.010\n",
            ">260, c1=-204.672, c2=-196.353 g=-214.707\n",
            ">261, c1=-207.095, c2=-199.057 g=-216.593\n",
            ">262, c1=-206.040, c2=-197.364 g=-217.154\n",
            ">263, c1=-208.305, c2=-199.686 g=-218.412\n",
            ">264, c1=-207.984, c2=-198.955 g=-218.144\n",
            ">265, c1=-208.115, c2=-202.568 g=-219.959\n",
            ">266, c1=-210.299, c2=-203.358 g=-221.267\n",
            ">267, c1=-211.453, c2=-203.982 g=-222.171\n",
            ">268, c1=-211.777, c2=-203.496 g=-222.341\n",
            ">269, c1=-213.920, c2=-206.225 g=-224.144\n",
            ">270, c1=-214.605, c2=-205.232 g=-224.612\n",
            ">271, c1=-214.457, c2=-207.346 g=-225.472\n",
            ">272, c1=-216.283, c2=-208.122 g=-226.629\n",
            ">273, c1=-216.470, c2=-209.561 g=-227.537\n",
            ">274, c1=-217.562, c2=-210.333 g=-228.570\n",
            ">275, c1=-219.713, c2=-211.063 g=-229.791\n",
            ">276, c1=-218.911, c2=-210.458 g=-230.307\n",
            ">277, c1=-220.122, c2=-210.600 g=-230.721\n",
            ">278, c1=-221.386, c2=-214.424 g=-232.220\n",
            ">279, c1=-222.442, c2=-215.341 g=-233.263\n",
            ">280, c1=-221.585, c2=-213.196 g=-232.552\n",
            ">281, c1=-222.974, c2=-217.390 g=-235.053\n",
            ">282, c1=-226.075, c2=-216.730 g=-235.216\n",
            ">283, c1=-225.238, c2=-219.621 g=-236.962\n",
            ">284, c1=-224.940, c2=-219.079 g=-237.867\n",
            ">285, c1=-227.915, c2=-219.589 g=-238.700\n",
            ">286, c1=-227.363, c2=-221.016 g=-239.149\n",
            ">287, c1=-229.489, c2=-222.994 g=-240.623\n",
            ">288, c1=-230.472, c2=-222.148 g=-241.322\n",
            ">289, c1=-231.300, c2=-223.242 g=-242.505\n",
            ">290, c1=-232.412, c2=-223.393 g=-243.319\n",
            ">291, c1=-233.303, c2=-221.884 g=-241.432\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: generated_plot_0291.png and model_0291.h5\n",
            ">292, c1=-232.801, c2=-228.301 g=-245.072\n",
            ">293, c1=-233.750, c2=-224.058 g=-244.779\n",
            ">294, c1=-234.890, c2=-228.453 g=-247.003\n",
            ">295, c1=-236.363, c2=-228.169 g=-247.875\n",
            ">296, c1=-237.868, c2=-228.721 g=-248.452\n",
            ">297, c1=-237.700, c2=-230.631 g=-249.131\n",
            ">298, c1=-238.652, c2=-232.242 g=-250.943\n",
            ">299, c1=-239.938, c2=-232.880 g=-250.804\n",
            ">300, c1=-241.374, c2=-235.209 g=-253.279\n",
            ">301, c1=-242.360, c2=-233.559 g=-253.135\n",
            ">302, c1=-243.415, c2=-235.630 g=-253.660\n",
            ">303, c1=-244.439, c2=-238.232 g=-255.920\n",
            ">304, c1=-245.430, c2=-235.766 g=-256.276\n",
            ">305, c1=-246.577, c2=-237.852 g=-257.020\n",
            ">306, c1=-245.960, c2=-239.752 g=-257.640\n",
            ">307, c1=-247.983, c2=-241.382 g=-259.265\n",
            ">308, c1=-248.526, c2=-232.484 g=-258.525\n",
            ">309, c1=-247.734, c2=-240.771 g=-259.233\n",
            ">310, c1=-248.806, c2=-243.810 g=-261.448\n",
            ">311, c1=-251.436, c2=-244.622 g=-263.010\n",
            ">312, c1=-252.626, c2=-244.562 g=-263.204\n",
            ">313, c1=-252.567, c2=-246.714 g=-265.010\n",
            ">314, c1=-250.465, c2=-240.243 g=-262.610\n",
            ">315, c1=-255.720, c2=-249.026 g=-266.975\n",
            ">316, c1=-256.397, c2=-247.628 g=-267.599\n",
            ">317, c1=-255.602, c2=-246.346 g=-265.833\n",
            ">318, c1=-257.529, c2=-251.460 g=-269.689\n",
            ">319, c1=-257.779, c2=-251.112 g=-270.166\n",
            ">320, c1=-257.565, c2=-250.652 g=-269.149\n",
            ">321, c1=-260.874, c2=-254.946 g=-272.477\n",
            ">322, c1=-260.193, c2=-254.267 g=-272.515\n",
            ">323, c1=-263.018, c2=-255.380 g=-274.336\n",
            ">324, c1=-262.989, c2=-254.152 g=-275.005\n",
            ">325, c1=-263.431, c2=-253.707 g=-274.163\n",
            ">326, c1=-264.656, c2=-259.005 g=-276.804\n",
            ">327, c1=-265.185, c2=-256.299 g=-276.893\n",
            ">328, c1=-266.839, c2=-257.254 g=-278.543\n",
            ">329, c1=-267.652, c2=-250.237 g=-277.153\n",
            ">330, c1=-266.176, c2=-256.584 g=-277.215\n",
            ">331, c1=-266.717, c2=-263.452 g=-279.859\n",
            ">332, c1=-269.056, c2=-264.059 g=-282.418\n",
            ">333, c1=-271.470, c2=-261.271 g=-283.779\n",
            ">334, c1=-269.323, c2=-256.781 g=-282.042\n",
            ">335, c1=-271.171, c2=-263.389 g=-284.257\n",
            ">336, c1=-271.320, c2=-265.594 g=-284.422\n",
            ">337, c1=-274.909, c2=-269.109 g=-286.313\n",
            ">338, c1=-276.132, c2=-270.148 g=-289.213\n",
            ">339, c1=-275.986, c2=-262.397 g=-288.116\n",
            ">340, c1=-276.336, c2=-265.584 g=-289.692\n",
            ">341, c1=-276.133, c2=-265.319 g=-289.051\n",
            ">342, c1=-279.150, c2=-270.748 g=-291.450\n",
            ">343, c1=-277.335, c2=-268.751 g=-291.312\n",
            ">344, c1=-278.925, c2=-272.909 g=-293.332\n",
            ">345, c1=-281.990, c2=-273.514 g=-294.717\n",
            ">346, c1=-281.048, c2=-269.963 g=-293.720\n",
            ">347, c1=-281.970, c2=-275.888 g=-296.153\n",
            ">348, c1=-282.024, c2=-275.537 g=-296.589\n",
            ">349, c1=-283.642, c2=-277.538 g=-298.709\n",
            ">350, c1=-283.511, c2=-276.628 g=-299.630\n",
            ">351, c1=-287.683, c2=-279.234 g=-301.582\n",
            ">352, c1=-287.425, c2=-268.862 g=-298.562\n",
            ">353, c1=-283.415, c2=-280.188 g=-299.811\n",
            ">354, c1=-287.812, c2=-284.224 g=-304.277\n",
            ">355, c1=-288.809, c2=-267.520 g=-302.396\n",
            ">356, c1=-288.515, c2=-272.883 g=-301.127\n",
            ">357, c1=-288.222, c2=-280.266 g=-304.160\n",
            ">358, c1=-291.122, c2=-278.409 g=-305.920\n",
            ">359, c1=-285.457, c2=-260.172 g=-301.601\n",
            ">360, c1=-287.578, c2=-277.080 g=-304.445\n",
            ">361, c1=-285.935, c2=-271.032 g=-303.857\n",
            ">362, c1=-285.567, c2=-279.258 g=-307.216\n",
            ">363, c1=-286.341, c2=-269.414 g=-306.144\n",
            ">364, c1=-286.392, c2=-277.430 g=-306.082\n",
            ">365, c1=-285.679, c2=-284.902 g=-308.931\n",
            ">366, c1=-292.615, c2=-286.473 g=-311.930\n",
            ">367, c1=-289.665, c2=-264.813 g=-307.095\n",
            ">368, c1=-290.826, c2=-283.335 g=-310.603\n",
            ">369, c1=-293.882, c2=-275.869 g=-310.871\n",
            ">370, c1=-289.415, c2=-274.635 g=-311.297\n",
            ">371, c1=-283.549, c2=-258.214 g=-308.052\n",
            ">372, c1=-284.660, c2=-282.952 g=-312.595\n",
            ">373, c1=-291.420, c2=-278.615 g=-311.611\n",
            ">374, c1=-281.877, c2=-269.104 g=-311.265\n",
            ">375, c1=-286.059, c2=-282.502 g=-312.782\n",
            ">376, c1=-289.076, c2=-283.060 g=-315.837\n",
            ">377, c1=-290.268, c2=-269.872 g=-312.536\n",
            ">378, c1=-294.037, c2=-279.988 g=-316.606\n",
            ">379, c1=-278.229, c2=-238.052 g=-309.020\n",
            ">380, c1=-281.226, c2=-257.786 g=-309.936\n",
            ">381, c1=-267.669, c2=-243.268 g=-304.488\n",
            ">382, c1=-257.007, c2=-243.681 g=-308.209\n",
            ">383, c1=-232.235, c2=-182.060 g=-298.368\n",
            ">384, c1=-217.524, c2=-204.835 g=-298.000\n",
            ">385, c1=-200.614, c2=-201.380 g=-292.511\n",
            ">386, c1=-230.273, c2=-246.339 g=-306.858\n",
            ">387, c1=-221.045, c2=-212.431 g=-303.922\n",
            ">388, c1=-227.577, c2=-215.240 g=-303.007\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: generated_plot_0388.png and model_0388.h5\n",
            ">389, c1=-238.325, c2=-202.920 g=-298.514\n",
            ">390, c1=-158.623, c2=-110.729 g=-285.636\n",
            ">391, c1=-159.758, c2=-90.902 g=-280.607\n",
            ">392, c1=-110.397, c2=-40.381 g=-258.615\n",
            ">393, c1=-61.149, c2=-17.147 g=-239.768\n",
            ">394, c1=-39.951, c2=44.346 g=-201.382\n",
            ">395, c1=-32.378, c2=60.731 g=-174.179\n",
            ">396, c1=-36.008, c2=50.310 g=-161.217\n",
            ">397, c1=-46.423, c2=43.861 g=-153.770\n",
            ">398, c1=-52.512, c2=27.192 g=-159.457\n",
            ">399, c1=-46.110, c2=28.462 g=-158.691\n",
            ">400, c1=-73.406, c2=27.318 g=-166.450\n",
            ">401, c1=-81.671, c2=21.393 g=-175.668\n",
            ">402, c1=-88.276, c2=21.326 g=-180.082\n",
            ">403, c1=-87.833, c2=6.323 g=-190.604\n",
            ">404, c1=-92.910, c2=-0.479 g=-198.419\n",
            ">405, c1=-103.351, c2=-11.627 g=-212.001\n",
            ">406, c1=-100.165, c2=-22.958 g=-219.278\n",
            ">407, c1=-103.222, c2=-8.968 g=-220.741\n",
            ">408, c1=-109.499, c2=-9.658 g=-226.257\n",
            ">409, c1=-114.414, c2=5.531 g=-226.877\n",
            ">410, c1=-127.193, c2=11.502 g=-225.335\n",
            ">411, c1=-123.648, c2=17.372 g=-223.729\n",
            ">412, c1=-124.200, c2=18.159 g=-222.456\n",
            ">413, c1=-123.391, c2=23.726 g=-221.813\n",
            ">414, c1=-131.150, c2=28.592 g=-216.379\n",
            ">415, c1=-129.201, c2=30.960 g=-216.258\n",
            ">416, c1=-134.073, c2=32.445 g=-213.704\n",
            ">417, c1=-132.866, c2=33.711 g=-211.619\n",
            ">418, c1=-142.854, c2=30.514 g=-212.010\n",
            ">419, c1=-148.114, c2=26.173 g=-211.140\n",
            ">420, c1=-152.262, c2=22.784 g=-212.753\n",
            ">421, c1=-160.368, c2=17.004 g=-209.421\n",
            ">422, c1=-156.903, c2=10.677 g=-207.511\n",
            ">423, c1=-160.932, c2=6.462 g=-205.236\n",
            ">424, c1=-173.922, c2=-2.082 g=-205.388\n",
            ">425, c1=-179.207, c2=-7.763 g=-202.722\n",
            ">426, c1=-177.360, c2=-15.498 g=-201.845\n",
            ">427, c1=-180.129, c2=-22.932 g=-199.666\n",
            ">428, c1=-185.012, c2=-27.697 g=-199.024\n",
            ">429, c1=-184.825, c2=-32.723 g=-195.618\n",
            ">430, c1=-193.303, c2=-39.750 g=-195.347\n",
            ">431, c1=-190.992, c2=-43.993 g=-190.604\n",
            ">432, c1=-206.011, c2=-48.491 g=-188.731\n",
            ">433, c1=-206.672, c2=-52.992 g=-182.181\n",
            ">434, c1=-212.530, c2=-64.369 g=-176.574\n",
            ">435, c1=-220.273, c2=-70.046 g=-172.030\n",
            ">436, c1=-223.869, c2=-80.240 g=-158.725\n",
            ">437, c1=-231.363, c2=-96.376 g=-143.380\n",
            ">438, c1=-235.607, c2=-103.418 g=-126.285\n",
            ">439, c1=-243.804, c2=-117.590 g=-106.541\n",
            ">440, c1=-250.009, c2=-126.546 g=-85.148\n",
            ">441, c1=-252.821, c2=-136.457 g=-63.867\n",
            ">442, c1=-260.148, c2=-142.254 g=-41.881\n",
            ">443, c1=-265.823, c2=-145.442 g=-20.485\n",
            ">444, c1=-267.921, c2=-147.691 g=-4.643\n",
            ">445, c1=-272.695, c2=-148.127 g=6.742\n",
            ">446, c1=-278.649, c2=-145.199 g=16.609\n",
            ">447, c1=-280.983, c2=-141.230 g=24.428\n",
            ">448, c1=-284.713, c2=-141.961 g=29.608\n",
            ">449, c1=-284.021, c2=-143.269 g=39.042\n",
            ">450, c1=-289.138, c2=-151.905 g=49.037\n",
            ">451, c1=-292.314, c2=-159.861 g=59.950\n",
            ">452, c1=-294.271, c2=-169.527 g=66.951\n",
            ">453, c1=-296.623, c2=-179.780 g=77.951\n",
            ">454, c1=-299.036, c2=-192.616 g=89.420\n",
            ">455, c1=-303.177, c2=-207.342 g=108.057\n",
            ">456, c1=-306.267, c2=-222.904 g=125.316\n",
            ">457, c1=-309.176, c2=-236.962 g=146.885\n",
            ">458, c1=-310.946, c2=-252.053 g=164.435\n",
            ">459, c1=-314.979, c2=-264.558 g=187.178\n",
            ">460, c1=-319.548, c2=-274.654 g=206.863\n",
            ">461, c1=-321.562, c2=-284.824 g=221.883\n",
            ">462, c1=-325.590, c2=-291.188 g=236.859\n",
            ">463, c1=-331.014, c2=-298.210 g=248.081\n",
            ">464, c1=-336.524, c2=-303.807 g=260.051\n",
            ">465, c1=-339.262, c2=-307.923 g=268.904\n",
            ">466, c1=-342.339, c2=-313.603 g=277.907\n",
            ">467, c1=-343.873, c2=-319.100 g=284.177\n",
            ">468, c1=-347.324, c2=-322.212 g=290.300\n",
            ">469, c1=-352.309, c2=-325.177 g=297.186\n",
            ">470, c1=-354.144, c2=-329.260 g=300.092\n",
            ">471, c1=-357.903, c2=-332.995 g=301.761\n",
            ">472, c1=-360.254, c2=-335.509 g=306.585\n",
            ">473, c1=-364.057, c2=-336.570 g=305.920\n",
            ">474, c1=-364.636, c2=-339.175 g=307.996\n",
            ">475, c1=-367.768, c2=-340.068 g=309.247\n",
            ">476, c1=-369.374, c2=-341.782 g=310.694\n",
            ">477, c1=-371.328, c2=-343.541 g=311.799\n",
            ">478, c1=-372.471, c2=-343.719 g=313.945\n",
            ">479, c1=-375.184, c2=-345.982 g=317.511\n",
            ">480, c1=-377.013, c2=-346.119 g=319.495\n",
            ">481, c1=-378.945, c2=-348.434 g=320.827\n",
            ">482, c1=-379.423, c2=-350.088 g=325.588\n",
            ">483, c1=-381.993, c2=-351.930 g=327.217\n",
            ">484, c1=-383.364, c2=-353.045 g=329.631\n",
            ">485, c1=-385.127, c2=-353.672 g=332.705\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: generated_plot_0485.png and model_0485.h5\n",
            ">486, c1=-385.544, c2=-355.660 g=334.852\n",
            ">487, c1=-388.030, c2=-356.654 g=334.719\n",
            ">488, c1=-388.517, c2=-357.465 g=339.020\n",
            ">489, c1=-390.228, c2=-358.680 g=340.166\n",
            ">490, c1=-390.634, c2=-359.128 g=340.892\n",
            ">491, c1=-394.575, c2=-359.458 g=343.596\n",
            ">492, c1=-395.267, c2=-361.619 g=347.421\n",
            ">493, c1=-396.155, c2=-364.288 g=347.866\n",
            ">494, c1=-399.224, c2=-366.701 g=351.686\n",
            ">495, c1=-400.429, c2=-368.909 g=355.242\n",
            ">496, c1=-403.064, c2=-371.177 g=357.780\n",
            ">497, c1=-406.381, c2=-373.910 g=360.316\n",
            ">498, c1=-405.118, c2=-376.440 g=363.487\n",
            ">499, c1=-408.606, c2=-379.095 g=366.634\n",
            ">500, c1=-408.292, c2=-380.723 g=368.787\n",
            ">501, c1=-410.603, c2=-382.901 g=371.268\n",
            ">502, c1=-412.958, c2=-384.869 g=373.627\n",
            ">503, c1=-415.726, c2=-386.483 g=376.026\n",
            ">504, c1=-417.339, c2=-387.702 g=378.169\n",
            ">505, c1=-419.296, c2=-389.307 g=381.125\n",
            ">506, c1=-421.563, c2=-390.575 g=382.958\n",
            ">507, c1=-422.545, c2=-391.584 g=385.117\n",
            ">508, c1=-425.325, c2=-393.031 g=387.108\n",
            ">509, c1=-423.969, c2=-393.892 g=388.550\n",
            ">510, c1=-427.281, c2=-394.714 g=390.298\n",
            ">511, c1=-428.445, c2=-395.714 g=391.441\n",
            ">512, c1=-429.995, c2=-396.135 g=392.709\n",
            ">513, c1=-431.523, c2=-396.643 g=392.877\n",
            ">514, c1=-432.416, c2=-397.080 g=394.025\n",
            ">515, c1=-435.334, c2=-397.570 g=394.907\n",
            ">516, c1=-435.274, c2=-398.451 g=396.288\n",
            ">517, c1=-438.390, c2=-399.586 g=397.854\n",
            ">518, c1=-439.043, c2=-401.025 g=399.108\n",
            ">519, c1=-439.927, c2=-402.816 g=400.420\n",
            ">520, c1=-442.609, c2=-403.908 g=401.905\n",
            ">521, c1=-443.431, c2=-405.004 g=403.223\n",
            ">522, c1=-445.964, c2=-406.463 g=404.574\n",
            ">523, c1=-447.500, c2=-407.581 g=406.199\n",
            ">524, c1=-448.044, c2=-408.560 g=407.254\n",
            ">525, c1=-448.618, c2=-409.863 g=408.686\n",
            ">526, c1=-450.364, c2=-411.035 g=410.002\n",
            ">527, c1=-451.719, c2=-412.212 g=411.348\n",
            ">528, c1=-453.891, c2=-413.421 g=412.582\n",
            ">529, c1=-454.561, c2=-414.604 g=413.794\n",
            ">530, c1=-456.975, c2=-415.788 g=415.159\n",
            ">531, c1=-457.833, c2=-416.848 g=416.450\n",
            ">532, c1=-460.192, c2=-417.991 g=417.613\n",
            ">533, c1=-461.509, c2=-419.260 g=418.832\n",
            ">534, c1=-462.982, c2=-420.469 g=420.041\n",
            ">535, c1=-463.167, c2=-421.628 g=421.468\n",
            ">536, c1=-465.439, c2=-422.759 g=422.707\n",
            ">537, c1=-466.122, c2=-423.998 g=423.918\n",
            ">538, c1=-467.976, c2=-425.102 g=424.989\n",
            ">539, c1=-468.496, c2=-426.273 g=426.248\n",
            ">540, c1=-469.486, c2=-427.473 g=427.404\n",
            ">541, c1=-472.014, c2=-428.643 g=428.733\n",
            ">542, c1=-473.400, c2=-429.755 g=429.840\n",
            ">543, c1=-474.269, c2=-430.906 g=431.102\n",
            ">544, c1=-477.167, c2=-432.023 g=432.244\n",
            ">545, c1=-475.685, c2=-433.246 g=433.317\n",
            ">546, c1=-479.866, c2=-434.476 g=434.570\n",
            ">547, c1=-479.798, c2=-435.604 g=435.688\n",
            ">548, c1=-481.476, c2=-436.876 g=436.941\n",
            ">549, c1=-481.546, c2=-437.922 g=438.025\n",
            ">550, c1=-482.222, c2=-439.001 g=439.122\n",
            ">551, c1=-484.262, c2=-440.230 g=440.058\n",
            ">552, c1=-486.137, c2=-441.313 g=441.523\n",
            ">553, c1=-486.901, c2=-442.299 g=442.648\n",
            ">554, c1=-487.747, c2=-443.465 g=443.646\n",
            ">555, c1=-489.229, c2=-444.606 g=444.981\n",
            ">556, c1=-490.304, c2=-445.836 g=445.988\n",
            ">557, c1=-492.117, c2=-446.946 g=447.325\n",
            ">558, c1=-492.739, c2=-448.157 g=448.294\n",
            ">559, c1=-493.357, c2=-449.231 g=449.490\n",
            ">560, c1=-495.938, c2=-450.285 g=450.717\n",
            ">561, c1=-497.719, c2=-451.595 g=451.903\n",
            ">562, c1=-497.632, c2=-452.842 g=452.965\n",
            ">563, c1=-500.409, c2=-454.110 g=454.248\n",
            ">564, c1=-500.567, c2=-455.126 g=455.196\n",
            ">565, c1=-501.742, c2=-456.398 g=456.441\n",
            ">566, c1=-503.822, c2=-457.639 g=457.631\n",
            ">567, c1=-504.865, c2=-458.391 g=458.831\n",
            ">568, c1=-504.837, c2=-459.719 g=459.900\n",
            ">569, c1=-507.157, c2=-460.941 g=461.126\n",
            ">570, c1=-508.850, c2=-462.093 g=462.271\n",
            ">571, c1=-509.429, c2=-463.060 g=463.437\n",
            ">572, c1=-512.246, c2=-464.323 g=464.539\n",
            ">573, c1=-512.251, c2=-465.420 g=465.730\n",
            ">574, c1=-514.527, c2=-466.531 g=466.904\n",
            ">575, c1=-515.450, c2=-467.768 g=468.014\n",
            ">576, c1=-515.270, c2=-468.782 g=469.169\n",
            ">577, c1=-517.540, c2=-470.037 g=470.430\n",
            ">578, c1=-518.853, c2=-471.123 g=471.539\n",
            ">579, c1=-520.169, c2=-472.230 g=472.786\n",
            ">580, c1=-522.466, c2=-473.327 g=473.859\n",
            ">581, c1=-521.405, c2=-474.561 g=474.956\n",
            ">582, c1=-522.867, c2=-475.682 g=476.142\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: generated_plot_0582.png and model_0582.h5\n",
            ">583, c1=-523.855, c2=-476.702 g=477.233\n",
            ">584, c1=-526.945, c2=-477.885 g=478.565\n",
            ">585, c1=-527.179, c2=-479.121 g=479.639\n",
            ">586, c1=-529.982, c2=-480.337 g=480.871\n",
            ">587, c1=-530.039, c2=-481.420 g=481.987\n",
            ">588, c1=-532.295, c2=-482.539 g=483.046\n",
            ">589, c1=-532.667, c2=-483.736 g=484.187\n",
            ">590, c1=-533.486, c2=-484.795 g=485.457\n",
            ">591, c1=-535.720, c2=-485.990 g=486.638\n",
            ">592, c1=-535.559, c2=-487.368 g=487.747\n",
            ">593, c1=-537.148, c2=-488.510 g=488.993\n",
            ">594, c1=-539.796, c2=-489.673 g=490.117\n",
            ">595, c1=-540.167, c2=-490.816 g=491.253\n",
            ">596, c1=-542.201, c2=-491.900 g=492.417\n",
            ">597, c1=-543.240, c2=-493.122 g=493.584\n",
            ">598, c1=-545.286, c2=-494.262 g=494.747\n",
            ">599, c1=-547.494, c2=-495.352 g=496.040\n",
            ">600, c1=-546.127, c2=-496.571 g=496.983\n",
            ">601, c1=-548.321, c2=-497.673 g=498.173\n",
            ">602, c1=-551.217, c2=-498.808 g=499.439\n",
            ">603, c1=-551.132, c2=-499.912 g=500.622\n",
            ">604, c1=-551.927, c2=-501.001 g=501.614\n",
            ">605, c1=-554.430, c2=-502.185 g=502.882\n",
            ">606, c1=-556.297, c2=-503.325 g=504.082\n",
            ">607, c1=-556.019, c2=-504.486 g=505.161\n",
            ">608, c1=-557.442, c2=-505.524 g=506.190\n",
            ">609, c1=-558.419, c2=-505.986 g=507.473\n",
            ">610, c1=-560.697, c2=-507.402 g=508.512\n",
            ">611, c1=-561.562, c2=-508.471 g=509.695\n",
            ">612, c1=-562.107, c2=-509.799 g=510.736\n",
            ">613, c1=-564.174, c2=-510.501 g=511.946\n",
            ">614, c1=-564.992, c2=-511.289 g=512.915\n",
            ">615, c1=-564.675, c2=-512.004 g=514.145\n",
            ">616, c1=-568.330, c2=-514.159 g=515.225\n",
            ">617, c1=-566.456, c2=-515.320 g=516.354\n",
            ">618, c1=-568.942, c2=-516.426 g=517.656\n",
            ">619, c1=-572.168, c2=-517.877 g=518.743\n",
            ">620, c1=-572.495, c2=-519.197 g=519.877\n",
            ">621, c1=-573.859, c2=-520.325 g=521.151\n",
            ">622, c1=-575.862, c2=-521.525 g=522.164\n",
            ">623, c1=-575.436, c2=-522.782 g=523.410\n",
            ">624, c1=-577.771, c2=-523.791 g=524.632\n",
            ">625, c1=-581.407, c2=-524.920 g=525.722\n",
            ">626, c1=-580.320, c2=-526.115 g=526.977\n",
            ">627, c1=-582.676, c2=-526.884 g=527.954\n",
            ">628, c1=-581.880, c2=-528.066 g=529.018\n",
            ">629, c1=-583.621, c2=-529.234 g=529.941\n",
            ">630, c1=-586.618, c2=-529.974 g=530.944\n",
            ">631, c1=-587.631, c2=-531.253 g=532.134\n",
            ">632, c1=-587.977, c2=-532.349 g=533.307\n",
            ">633, c1=-589.057, c2=-533.223 g=534.558\n",
            ">634, c1=-589.764, c2=-534.730 g=535.552\n",
            ">635, c1=-593.095, c2=-535.453 g=536.841\n",
            ">636, c1=-593.414, c2=-535.092 g=537.718\n",
            ">637, c1=-595.939, c2=-535.284 g=539.085\n",
            ">638, c1=-597.250, c2=-537.553 g=540.254\n",
            ">639, c1=-597.642, c2=-536.014 g=541.304\n",
            ">640, c1=-598.349, c2=-538.106 g=542.193\n",
            ">641, c1=-600.167, c2=-537.959 g=543.336\n",
            ">642, c1=-599.890, c2=-537.925 g=544.373\n",
            ">643, c1=-602.640, c2=-537.274 g=545.365\n",
            ">644, c1=-602.675, c2=-536.859 g=546.003\n",
            ">645, c1=-604.478, c2=-536.801 g=546.727\n",
            ">646, c1=-604.369, c2=-535.651 g=547.607\n",
            ">647, c1=-605.422, c2=-533.574 g=548.322\n",
            ">648, c1=-605.319, c2=-529.582 g=548.856\n",
            ">649, c1=-606.329, c2=-526.291 g=548.681\n",
            ">650, c1=-607.197, c2=-521.427 g=548.292\n",
            ">651, c1=-606.541, c2=-520.767 g=547.578\n",
            ">652, c1=-606.756, c2=-519.382 g=546.588\n",
            ">653, c1=-608.513, c2=-513.289 g=545.805\n",
            ">654, c1=-608.533, c2=-512.387 g=544.224\n",
            ">655, c1=-608.385, c2=-517.895 g=545.028\n",
            ">656, c1=-608.805, c2=-520.575 g=545.283\n",
            ">657, c1=-611.629, c2=-526.213 g=546.021\n",
            ">658, c1=-612.772, c2=-529.120 g=547.980\n",
            ">659, c1=-613.564, c2=-536.180 g=550.248\n",
            ">660, c1=-614.536, c2=-542.292 g=551.977\n",
            ">661, c1=-617.031, c2=-543.106 g=553.385\n",
            ">662, c1=-619.145, c2=-551.371 g=556.473\n",
            ">663, c1=-619.340, c2=-552.396 g=558.124\n",
            ">664, c1=-621.682, c2=-551.519 g=560.205\n",
            ">665, c1=-622.896, c2=-553.830 g=560.639\n",
            ">666, c1=-624.240, c2=-554.791 g=560.860\n",
            ">667, c1=-626.035, c2=-557.267 g=563.080\n",
            ">668, c1=-626.373, c2=-556.757 g=564.091\n",
            ">669, c1=-627.678, c2=-560.024 g=565.404\n",
            ">670, c1=-627.380, c2=-561.525 g=565.537\n",
            ">671, c1=-630.691, c2=-562.782 g=567.168\n",
            ">672, c1=-631.791, c2=-561.700 g=568.893\n",
            ">673, c1=-632.723, c2=-563.745 g=570.209\n",
            ">674, c1=-633.820, c2=-566.278 g=571.026\n",
            ">675, c1=-636.893, c2=-566.409 g=572.669\n",
            ">676, c1=-637.500, c2=-569.307 g=573.260\n",
            ">677, c1=-638.970, c2=-569.031 g=574.368\n",
            ">678, c1=-638.486, c2=-572.650 g=576.469\n",
            ">679, c1=-641.120, c2=-573.072 g=577.587\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: generated_plot_0679.png and model_0679.h5\n",
            ">680, c1=-642.572, c2=-576.108 g=579.506\n",
            ">681, c1=-644.421, c2=-577.802 g=580.910\n",
            ">682, c1=-643.363, c2=-578.348 g=582.123\n",
            ">683, c1=-646.198, c2=-579.462 g=583.148\n",
            ">684, c1=-648.133, c2=-578.345 g=584.617\n",
            ">685, c1=-650.537, c2=-573.438 g=583.002\n",
            ">686, c1=-651.262, c2=-567.844 g=582.611\n",
            ">687, c1=-651.033, c2=-553.962 g=579.518\n",
            ">688, c1=-649.133, c2=-541.350 g=580.591\n",
            ">689, c1=-649.338, c2=-544.687 g=578.665\n",
            ">690, c1=-651.154, c2=-550.306 g=579.591\n",
            ">691, c1=-650.329, c2=-548.943 g=577.827\n",
            ">692, c1=-651.232, c2=-555.071 g=580.217\n",
            ">693, c1=-652.076, c2=-559.255 g=581.976\n",
            ">694, c1=-652.407, c2=-557.395 g=582.042\n",
            ">695, c1=-654.975, c2=-552.665 g=580.760\n",
            ">696, c1=-652.856, c2=-547.691 g=582.782\n",
            ">697, c1=-651.797, c2=-544.057 g=582.665\n",
            ">698, c1=-651.366, c2=-542.419 g=581.983\n",
            ">699, c1=-650.907, c2=-523.320 g=579.369\n",
            ">700, c1=-647.399, c2=-512.136 g=575.413\n",
            ">701, c1=-645.895, c2=-506.302 g=572.222\n",
            ">702, c1=-642.153, c2=-504.430 g=570.874\n",
            ">703, c1=-642.533, c2=-501.390 g=565.490\n",
            ">704, c1=-638.660, c2=-504.336 g=566.803\n",
            ">705, c1=-636.890, c2=-500.744 g=559.614\n",
            ">706, c1=-636.330, c2=-500.950 g=560.801\n",
            ">707, c1=-638.930, c2=-494.738 g=553.705\n",
            ">708, c1=-639.936, c2=-502.451 g=555.545\n",
            ">709, c1=-643.371, c2=-504.759 g=559.518\n",
            ">710, c1=-643.158, c2=-512.370 g=555.661\n",
            ">711, c1=-645.814, c2=-523.025 g=557.578\n",
            ">712, c1=-650.189, c2=-531.047 g=568.263\n",
            ">713, c1=-656.635, c2=-540.883 g=573.751\n",
            ">714, c1=-660.151, c2=-552.430 g=581.556\n",
            ">715, c1=-662.093, c2=-571.999 g=590.099\n",
            ">716, c1=-666.827, c2=-568.750 g=592.240\n",
            ">717, c1=-671.178, c2=-575.433 g=590.197\n",
            ">718, c1=-672.687, c2=-585.916 g=597.518\n",
            ">719, c1=-677.715, c2=-596.928 g=606.014\n",
            ">720, c1=-680.668, c2=-604.212 g=613.026\n",
            ">721, c1=-682.973, c2=-606.839 g=616.388\n",
            ">722, c1=-685.411, c2=-608.023 g=616.769\n",
            ">723, c1=-689.154, c2=-612.554 g=618.849\n",
            ">724, c1=-691.875, c2=-615.051 g=624.075\n",
            ">725, c1=-693.620, c2=-615.673 g=626.004\n",
            ">726, c1=-696.879, c2=-621.444 g=627.862\n",
            ">727, c1=-697.545, c2=-617.701 g=628.245\n",
            ">728, c1=-699.115, c2=-621.994 g=630.269\n",
            ">729, c1=-700.602, c2=-621.773 g=628.514\n",
            ">730, c1=-702.915, c2=-622.782 g=631.780\n",
            ">731, c1=-704.176, c2=-623.287 g=633.870\n",
            ">732, c1=-706.028, c2=-625.157 g=634.449\n",
            ">733, c1=-706.527, c2=-622.384 g=636.910\n",
            ">734, c1=-709.057, c2=-623.811 g=636.562\n",
            ">735, c1=-709.332, c2=-628.429 g=636.332\n",
            ">736, c1=-710.035, c2=-622.216 g=634.526\n",
            ">737, c1=-711.453, c2=-623.994 g=639.154\n",
            ">738, c1=-712.182, c2=-621.117 g=639.960\n",
            ">739, c1=-713.382, c2=-621.152 g=638.218\n",
            ">740, c1=-712.743, c2=-618.198 g=639.511\n",
            ">741, c1=-715.777, c2=-621.616 g=637.355\n",
            ">742, c1=-715.661, c2=-619.671 g=636.810\n",
            ">743, c1=-714.955, c2=-620.047 g=638.930\n",
            ">744, c1=-718.955, c2=-625.091 g=639.391\n",
            ">745, c1=-718.602, c2=-614.720 g=635.180\n",
            ">746, c1=-720.400, c2=-617.283 g=631.851\n",
            ">747, c1=-720.222, c2=-615.661 g=630.778\n",
            ">748, c1=-720.942, c2=-600.128 g=620.980\n",
            ">749, c1=-720.732, c2=-594.117 g=617.147\n",
            ">750, c1=-720.929, c2=-578.649 g=605.752\n",
            ">751, c1=-721.513, c2=-573.217 g=586.412\n",
            ">752, c1=-719.727, c2=-530.912 g=561.386\n",
            ">753, c1=-717.559, c2=-526.635 g=534.231\n",
            ">754, c1=-719.300, c2=-524.324 g=517.513\n",
            ">755, c1=-719.755, c2=-522.856 g=514.640\n",
            ">756, c1=-720.140, c2=-522.768 g=508.183\n",
            ">757, c1=-719.144, c2=-517.731 g=508.370\n",
            ">758, c1=-719.524, c2=-534.909 g=514.764\n",
            ">759, c1=-720.102, c2=-537.256 g=517.596\n",
            ">760, c1=-719.852, c2=-542.292 g=525.860\n",
            ">761, c1=-721.043, c2=-546.959 g=529.300\n",
            ">762, c1=-723.938, c2=-559.758 g=536.046\n",
            ">763, c1=-724.894, c2=-569.671 g=537.470\n",
            ">764, c1=-726.351, c2=-574.495 g=542.901\n",
            ">765, c1=-728.825, c2=-581.632 g=545.520\n",
            ">766, c1=-728.784, c2=-583.810 g=551.503\n",
            ">767, c1=-729.644, c2=-594.542 g=551.652\n",
            ">768, c1=-732.308, c2=-599.126 g=551.086\n",
            ">769, c1=-732.340, c2=-600.889 g=566.418\n",
            ">770, c1=-732.348, c2=-609.654 g=564.622\n",
            ">771, c1=-731.477, c2=-612.736 g=553.401\n",
            ">772, c1=-733.489, c2=-614.488 g=553.737\n",
            ">773, c1=-734.257, c2=-616.583 g=549.196\n",
            ">774, c1=-732.764, c2=-616.434 g=539.556\n",
            ">775, c1=-729.941, c2=-609.279 g=535.094\n",
            ">776, c1=-728.440, c2=-605.719 g=525.160\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: generated_plot_0776.png and model_0776.h5\n",
            ">777, c1=-729.322, c2=-605.685 g=513.703\n",
            ">778, c1=-729.303, c2=-594.156 g=503.630\n",
            ">779, c1=-726.661, c2=-592.769 g=471.046\n",
            ">780, c1=-724.691, c2=-567.911 g=436.877\n",
            ">781, c1=-713.647, c2=-549.413 g=424.489\n",
            ">782, c1=-707.670, c2=-522.598 g=436.224\n",
            ">783, c1=-698.088, c2=-506.014 g=440.767\n",
            ">784, c1=-690.143, c2=-509.144 g=452.929\n",
            ">785, c1=-689.277, c2=-490.003 g=464.812\n",
            ">786, c1=-686.430, c2=-501.317 g=473.026\n",
            ">787, c1=-683.636, c2=-508.252 g=475.440\n",
            ">788, c1=-687.840, c2=-514.323 g=489.607\n",
            ">789, c1=-688.203, c2=-510.096 g=496.205\n",
            ">790, c1=-691.060, c2=-516.016 g=498.784\n",
            ">791, c1=-692.555, c2=-522.200 g=497.794\n",
            ">792, c1=-694.216, c2=-515.121 g=513.138\n",
            ">793, c1=-700.237, c2=-522.051 g=512.926\n",
            ">794, c1=-704.593, c2=-526.684 g=510.661\n",
            ">795, c1=-705.677, c2=-531.261 g=505.871\n",
            ">796, c1=-706.701, c2=-537.326 g=516.052\n",
            ">797, c1=-703.222, c2=-545.985 g=519.932\n",
            ">798, c1=-706.308, c2=-555.897 g=519.831\n",
            ">799, c1=-703.041, c2=-548.791 g=527.710\n",
            ">800, c1=-703.097, c2=-552.913 g=528.454\n",
            ">801, c1=-701.264, c2=-540.394 g=520.713\n",
            ">802, c1=-701.195, c2=-538.053 g=508.808\n",
            ">803, c1=-692.253, c2=-523.907 g=486.853\n",
            ">804, c1=-677.770, c2=-499.961 g=460.441\n",
            ">805, c1=-673.269, c2=-488.998 g=401.474\n",
            ">806, c1=-663.336, c2=-455.978 g=374.108\n",
            ">807, c1=-652.589, c2=-448.201 g=354.379\n",
            ">808, c1=-647.900, c2=-437.084 g=353.962\n",
            ">809, c1=-646.217, c2=-443.496 g=306.388\n",
            ">810, c1=-634.268, c2=-381.532 g=263.545\n",
            ">811, c1=-626.371, c2=-297.549 g=99.235\n",
            ">812, c1=-603.490, c2=-148.731 g=-47.786\n",
            ">813, c1=-556.786, c2=-46.162 g=-128.124\n",
            ">814, c1=-533.591, c2=-4.889 g=-161.701\n",
            ">815, c1=-507.694, c2=-28.550 g=-197.354\n",
            ">816, c1=-501.097, c2=-80.288 g=-250.925\n",
            ">817, c1=-485.323, c2=25.944 g=-265.846\n",
            ">818, c1=-482.416, c2=-79.490 g=-329.395\n",
            ">819, c1=-486.551, c2=-69.736 g=-339.987\n",
            ">820, c1=-469.020, c2=-107.874 g=-362.159\n",
            ">821, c1=-495.058, c2=-188.129 g=-425.664\n",
            ">822, c1=-488.432, c2=-204.317 g=-443.671\n",
            ">823, c1=-509.210, c2=-300.919 g=-474.375\n",
            ">824, c1=-527.099, c2=-355.956 g=-515.044\n",
            ">825, c1=-549.831, c2=-366.283 g=-515.438\n",
            ">826, c1=-543.022, c2=-388.209 g=-543.403\n",
            ">827, c1=-557.794, c2=-402.004 g=-564.907\n",
            ">828, c1=-561.441, c2=-444.154 g=-581.328\n",
            ">829, c1=-581.598, c2=-438.666 g=-591.212\n",
            ">830, c1=-576.159, c2=-437.437 g=-594.691\n",
            ">831, c1=-582.720, c2=-441.587 g=-595.035\n",
            ">832, c1=-585.923, c2=-457.041 g=-604.819\n",
            ">833, c1=-584.634, c2=-464.003 g=-622.840\n",
            ">834, c1=-591.490, c2=-425.503 g=-615.102\n",
            ">835, c1=-600.480, c2=-460.476 g=-610.512\n",
            ">836, c1=-583.193, c2=-447.140 g=-620.692\n",
            ">837, c1=-581.623, c2=-412.415 g=-619.683\n",
            ">838, c1=-548.227, c2=-331.593 g=-604.543\n",
            ">839, c1=-553.805, c2=-405.249 g=-613.108\n",
            ">840, c1=-564.759, c2=-392.781 g=-604.901\n",
            ">841, c1=-507.836, c2=-242.422 g=-599.574\n",
            ">842, c1=-470.890, c2=-185.648 g=-595.368\n",
            ">843, c1=-454.433, c2=-153.084 g=-578.798\n",
            ">844, c1=-449.723, c2=-50.001 g=-557.746\n",
            ">845, c1=-470.405, c2=-93.019 g=-558.572\n",
            ">846, c1=-444.218, c2=148.954 g=-525.625\n",
            ">847, c1=-410.545, c2=165.437 g=-525.830\n",
            ">848, c1=-418.327, c2=150.247 g=-503.124\n",
            ">849, c1=-418.489, c2=141.264 g=-481.303\n",
            ">850, c1=-425.677, c2=194.547 g=-473.673\n",
            ">851, c1=-427.326, c2=244.479 g=-455.092\n",
            ">852, c1=-434.487, c2=223.237 g=-440.850\n",
            ">853, c1=-415.045, c2=18.463 g=-468.577\n",
            ">854, c1=-411.251, c2=51.888 g=-470.713\n",
            ">855, c1=-401.737, c2=133.734 g=-445.322\n",
            ">856, c1=-406.871, c2=22.674 g=-472.962\n",
            ">857, c1=-372.656, c2=68.154 g=-465.657\n",
            ">858, c1=-358.272, c2=211.208 g=-448.260\n",
            ">859, c1=-413.093, c2=42.966 g=-446.827\n",
            ">860, c1=-376.637, c2=93.432 g=-444.975\n",
            ">861, c1=-380.630, c2=26.235 g=-464.619\n",
            ">862, c1=-378.181, c2=109.789 g=-453.697\n",
            ">863, c1=-377.566, c2=68.845 g=-450.922\n",
            ">864, c1=-366.659, c2=145.671 g=-446.052\n",
            ">865, c1=-393.969, c2=32.298 g=-468.197\n",
            ">866, c1=-351.512, c2=125.389 g=-477.138\n",
            ">867, c1=-363.863, c2=73.507 g=-463.033\n",
            ">868, c1=-394.168, c2=64.701 g=-473.638\n",
            ">869, c1=-382.204, c2=-62.195 g=-484.468\n",
            ">870, c1=-373.062, c2=98.021 g=-486.663\n",
            ">871, c1=-379.412, c2=18.811 g=-485.160\n",
            ">872, c1=-403.204, c2=288.544 g=-464.895\n",
            ">873, c1=-352.721, c2=194.865 g=-469.339\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: generated_plot_0873.png and model_0873.h5\n",
            ">874, c1=-370.430, c2=55.119 g=-486.547\n",
            ">875, c1=-391.950, c2=-31.839 g=-507.678\n",
            ">876, c1=-377.396, c2=77.047 g=-495.269\n",
            ">877, c1=-339.839, c2=136.548 g=-498.973\n",
            ">878, c1=-356.526, c2=184.546 g=-473.581\n",
            ">879, c1=-377.954, c2=127.408 g=-480.148\n",
            ">880, c1=-360.587, c2=214.187 g=-463.257\n",
            ">881, c1=-364.226, c2=76.963 g=-477.785\n",
            ">882, c1=-384.087, c2=134.259 g=-468.822\n",
            ">883, c1=-345.725, c2=80.518 g=-477.133\n",
            ">884, c1=-365.735, c2=202.084 g=-457.704\n",
            ">885, c1=-361.849, c2=185.652 g=-457.126\n",
            ">886, c1=-340.169, c2=241.426 g=-448.759\n",
            ">887, c1=-374.793, c2=274.619 g=-434.130\n",
            ">888, c1=-387.356, c2=297.679 g=-432.304\n",
            ">889, c1=-384.891, c2=314.105 g=-421.016\n",
            ">890, c1=-389.296, c2=182.868 g=-432.728\n",
            ">891, c1=-377.458, c2=192.328 g=-431.813\n",
            ">892, c1=-318.549, c2=174.743 g=-440.527\n",
            ">893, c1=-370.648, c2=135.202 g=-452.646\n",
            ">894, c1=-359.017, c2=105.738 g=-450.549\n",
            ">895, c1=-316.463, c2=107.947 g=-458.260\n",
            ">896, c1=-332.084, c2=182.229 g=-453.587\n",
            ">897, c1=-317.995, c2=165.009 g=-449.209\n",
            ">898, c1=-297.984, c2=194.144 g=-458.650\n",
            ">899, c1=-321.987, c2=186.343 g=-452.665\n",
            ">900, c1=-305.579, c2=176.353 g=-451.882\n",
            ">901, c1=-340.290, c2=99.181 g=-459.420\n",
            ">902, c1=-333.278, c2=130.811 g=-453.678\n",
            ">903, c1=-323.222, c2=168.457 g=-445.096\n",
            ">904, c1=-307.083, c2=150.108 g=-426.871\n",
            ">905, c1=-345.299, c2=331.164 g=-423.201\n",
            ">906, c1=-357.480, c2=241.995 g=-441.554\n",
            ">907, c1=-364.172, c2=321.812 g=-420.049\n",
            ">908, c1=-371.724, c2=275.550 g=-422.284\n",
            ">909, c1=-376.549, c2=258.383 g=-419.277\n",
            ">910, c1=-359.910, c2=275.152 g=-410.749\n",
            ">911, c1=-369.100, c2=221.905 g=-420.802\n",
            ">912, c1=-356.564, c2=236.907 g=-415.133\n",
            ">913, c1=-334.004, c2=215.240 g=-410.690\n",
            ">914, c1=-360.265, c2=202.647 g=-415.117\n",
            ">915, c1=-350.650, c2=267.050 g=-405.555\n",
            ">916, c1=-360.978, c2=287.354 g=-398.090\n",
            ">917, c1=-362.931, c2=314.612 g=-376.796\n",
            ">918, c1=-374.223, c2=223.171 g=-411.617\n",
            ">919, c1=-341.416, c2=223.223 g=-404.762\n",
            ">920, c1=-362.933, c2=202.486 g=-413.236\n",
            ">921, c1=-322.291, c2=196.663 g=-423.119\n",
            ">922, c1=-335.231, c2=135.056 g=-414.085\n",
            ">923, c1=-277.670, c2=188.892 g=-413.154\n",
            ">924, c1=-339.572, c2=165.373 g=-418.620\n",
            ">925, c1=-295.415, c2=232.602 g=-389.429\n",
            ">926, c1=-345.807, c2=245.911 g=-386.154\n",
            ">927, c1=-342.892, c2=217.829 g=-372.070\n",
            ">928, c1=-339.233, c2=264.252 g=-364.841\n",
            ">929, c1=-345.063, c2=303.725 g=-339.546\n",
            ">930, c1=-357.759, c2=266.853 g=-356.871\n",
            ">931, c1=-356.948, c2=276.449 g=-350.050\n",
            ">932, c1=-351.618, c2=286.289 g=-324.099\n",
            ">933, c1=-344.431, c2=212.056 g=-348.275\n",
            ">934, c1=-337.136, c2=184.162 g=-362.787\n",
            ">935, c1=-325.032, c2=150.161 g=-379.332\n",
            ">936, c1=-313.405, c2=212.927 g=-369.157\n",
            ">937, c1=-322.661, c2=226.452 g=-357.057\n",
            ">938, c1=-335.350, c2=193.701 g=-355.048\n",
            ">939, c1=-334.634, c2=225.384 g=-357.107\n",
            ">940, c1=-327.921, c2=198.355 g=-360.807\n",
            ">941, c1=-325.193, c2=251.181 g=-337.171\n",
            ">942, c1=-338.155, c2=227.673 g=-351.891\n",
            ">943, c1=-329.958, c2=237.739 g=-331.085\n",
            ">944, c1=-322.354, c2=242.770 g=-326.006\n",
            ">945, c1=-330.034, c2=242.201 g=-314.073\n",
            ">946, c1=-319.119, c2=250.718 g=-313.197\n",
            ">947, c1=-335.822, c2=253.454 g=-322.816\n",
            ">948, c1=-335.044, c2=259.205 g=-311.918\n",
            ">949, c1=-327.240, c2=251.109 g=-292.467\n",
            ">950, c1=-320.096, c2=243.242 g=-285.578\n",
            ">951, c1=-324.741, c2=248.199 g=-287.188\n",
            ">952, c1=-329.243, c2=248.940 g=-290.205\n",
            ">953, c1=-314.943, c2=253.946 g=-257.220\n",
            ">954, c1=-312.689, c2=244.105 g=-251.712\n",
            ">955, c1=-301.491, c2=227.535 g=-225.822\n",
            ">956, c1=-303.272, c2=235.773 g=-228.887\n",
            ">957, c1=-295.181, c2=225.807 g=-218.872\n",
            ">958, c1=-287.720, c2=211.508 g=-217.893\n",
            ">959, c1=-296.752, c2=214.185 g=-220.838\n",
            ">960, c1=-294.521, c2=201.568 g=-216.598\n",
            ">961, c1=-288.491, c2=160.027 g=-247.958\n",
            ">962, c1=-294.458, c2=173.235 g=-252.012\n",
            ">963, c1=-292.664, c2=167.186 g=-264.646\n",
            ">964, c1=-295.622, c2=225.554 g=-262.215\n",
            ">965, c1=-297.464, c2=234.522 g=-246.403\n",
            ">966, c1=-310.745, c2=221.557 g=-262.064\n",
            ">967, c1=-283.401, c2=179.103 g=-257.847\n",
            ">968, c1=-289.143, c2=181.912 g=-265.060\n",
            ">969, c1=-276.215, c2=176.962 g=-267.074\n",
            ">970, c1=-288.963, c2=192.777 g=-259.182\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: generated_plot_0970.png and model_0970.h5\n"
          ]
        }
      ]
    }
  ]
}